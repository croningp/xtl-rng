{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import sys\n",
    "import inspect\n",
    "import logging\n",
    "import skimage.draw\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "%matplotlib inline\n",
    "\n",
    "# add datetime to every logging message\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.basicConfig( format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# this get our current location in the file system\n",
    "HERE_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "MRCNN_PATH = os.path.join(HERE_PATH, 'Mask_RCNN')\n",
    "# adding parent directory to path, so we can access the utils easily\n",
    "sys.path.append(HERE_PATH)\n",
    "sys.path.append(MRCNN_PATH)\n",
    "\n",
    "# import mrcnn libraries\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if we are using Windows or Linux filing conventions and assign root folders\n",
    "if sys.platform == 'win32':\n",
    "    SCAPA_ROOT = os.path.join('Z:', os.sep, 'group')\n",
    "    ORKNEY_ROOT = os.path.join('U:', os.sep)\n",
    "else:\n",
    "    SCAPA_ROOT = '/mnt/scapa4'\n",
    "    ORKNEY_ROOT  ='/mnt/orkney1'\n",
    "\n",
    "ORKNEY_TEAM = os.path.join(ORKNEY_ROOT, 'Clusters')\n",
    "ORKNEY_PROJECT = os.path.join(ORKNEY_TEAM, 'RandomXtl')\n",
    "ORKNEY_MASKRCNN = os.path.join(ORKNEY_PROJECT, 'MaskRCNN')\n",
    "ORKNEY_DETECTED = os.path.join(ORKNEY_MASKRCNN, 'detected')\n",
    "ORKNEY_TRAINING = os.path.join(ORKNEY_MASKRCNN, 'training')\n",
    "ORKNEY_DATASETS = os.path.join(ORKNEY_TRAINING, 'datasets')\n",
    "ORKNEY_LOGS = os.path.join(ORKNEY_TRAINING, 'logs')\n",
    "\n",
    "ORKNEY_IMAGES = os.path.join(ORKNEY_PROJECT, 'images')\n",
    "ORKNEY_RAW_IMGS = os.path.join(ORKNEY_IMAGES, 'raw_images')\n",
    "ORKNEY_PART_IMGS = os.path.join(ORKNEY_IMAGES, 'partitioned')\n",
    "\n",
    "ORKNEY_CV = os.path.join(ORKNEY_PROJECT, 'computer_vision')\n",
    "\n",
    "IMG_EXTS = ['.img', '.bmp', '.tiff', '.jpg', '.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Name          Timestamp     Epochs\n",
      "crystals             20190709T1706     30\n",
      "mof5_multi           20190710T1531     30\n",
      "mof5_single          20190711T1533     30\n",
      "mof5_single_split    20190712T1112     30\n",
      "mof5_twinned_split   20190712T1509     30\n",
      "mof5_ac_all          20190724T1205     30\n",
      "w19                  20190820T1718     30\n",
      "w19(2)               20190822T1225     11\n",
      "w19(2)               20190822T1644     0\n",
      "w19_3_               20190822T1647     0\n"
     ]
    }
   ],
   "source": [
    "def get_models():\n",
    "    models = {}\n",
    "    for model_dir in os.listdir(ORKNEY_LOGS):\n",
    "        model_dir_path = os.path.join(ORKNEY_LOGS, model_dir)\n",
    "        object_name, timestamp = model_dir[:-13], model_dir[-13:]\n",
    "        epoch_names = sorted(filter(lambda f: f.endswith('.h5'), os.listdir(model_dir_path)))\n",
    "        epoch_paths = [os.path.join(model_dir_path, f) for f in epoch_names]\n",
    "        epochs = len(epoch_paths)\n",
    "\n",
    "        if object_name not in models.keys():\n",
    "            models[object_name] = []\n",
    "        this_dict = {'name': model_dir, 'stamp': timestamp, 'path': model_dir_path,\n",
    "                     'epochs': epochs, 'epoch_paths': epoch_paths}\n",
    "        models[object_name].append(this_dict)\n",
    "    return models\n",
    "    \n",
    "def show_models():\n",
    "    \n",
    "    print('Object Name'.ljust(21)+'Timestamp'.ljust(14) +'Epochs')\n",
    "    for k, v in MODELS.items():   \n",
    "        for data in v:\n",
    "            print(k.ljust(20), data['stamp'].ljust(17), data['epochs'])    \n",
    "            \n",
    "MODELS = get_models()\n",
    "show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 10:36:26.991095 139802853308032 <ipython-input-39-21a89a327bb8>:62] Detecting from chunk: 0/1, 0:800, 0:0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 30\n",
      "Processing 1 images\n",
      "image                    shape: (800, 1280, 3)        min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 640, 640, 3)      min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1280.00000  float64\n",
      "anchors                  shape: (1, 102300, 4)        min:   -0.28329  max:    1.18313  float32\n",
      "p1 304 287\n",
      "p2 (0, 304)\n",
      "p1 556 682\n",
      "p2 (499, 556)\n"
     ]
    }
   ],
   "source": [
    "class Detector:\n",
    "\n",
    "    def __init__(self, target_object, model_version=-1, epoch=-1):\n",
    "        \n",
    "        from detecting.detect_cfg import InferenceConfig, CrystalsConfig\n",
    "        \n",
    "        self.target_object = target_object.lower()\n",
    "        self.output_root_dir = os.path.join(ORKNEY_DETECTED, target_object.lower())\n",
    "        \n",
    "        self.inference_config = InferenceConfig()\n",
    "        self.crystals_config = CrystalsConfig()\n",
    "\n",
    "        self.model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=self.inference_config,\n",
    "                          model_dir=ORKNEY_LOGS)\n",
    "        self.model_path = MODELS[self.target_object][model_version]['epoch_paths'][epoch]\n",
    "        self.model.load_weights(self.model_path, by_name=True)\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "    def detect_path(self, input_path, partitioning = [1,1,0], save=False, show=False):\n",
    "        # unpack arguments\n",
    "        self.input_path = input_path\n",
    "        self.rows, self.cols, self.overlap = partitioning\n",
    "        self.save = save\n",
    "        self.show = show\n",
    "        \n",
    "        # assign folders for output files\n",
    "        self.image_title, self.image_ext = os.path.basename(input_path).split('.')\n",
    "\n",
    "        self.reaction_path = os.path.dirname(os.path.dirname(input_path))\n",
    "        self.rxn_id = os.path.basename(self.reaction_path)\n",
    "        self.exp_path = os.path.dirname(self.reaction_path)\n",
    "        self.exp_id = os.path.basename(self.exp_path)\n",
    "        \n",
    "        self.output_dir = os.path.join(self.output_root_dir, self.exp_id, self.rxn_id, self.image_title)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        # duplicate image to output folder\n",
    "        self.duplicate_path = os.path.join(self.output_dir, os.path.basename(input_path))\n",
    "        cv2.imwrite(self.duplicate_path, cv2.imread(input_path))\n",
    "        \n",
    "        #load and reverse image (maskrccn does weird things pparaently....)\n",
    "        self.img = cv2.imread(input_path)       \n",
    "        self.image_rev = self.img[:,::-1]\n",
    "        self.image_height, self.image_width = self.img.shape[:2]  \n",
    "            \n",
    "        self.get_rois(self.image_rev, self.rows, self.cols, self.overlap)\n",
    "\n",
    "       # dict for collating detections from separate image chunks in the same format as maskrcnn\n",
    "        self.all_rs = {'rois':np.empty((0,4)),\n",
    "                      'masks':np.empty((self.image_height, self.image_width, 0)),\n",
    "                      'class_ids':np.empty(0)}\n",
    "        \n",
    "        self.detection_data = []\n",
    "        \n",
    "        for idx, roi in enumerate(self.roi_regions):\n",
    "            \n",
    "            image_roi = self.image_rev[roi['t']:roi['b'], roi['l']: roi['r']]\n",
    "            logging.info('Detecting from chunk: {}/{}, {}:{}, {}:{}]'.format(\\\n",
    "                    idx, len(self.roi_regions), roi['t'],roi['b'],roi['t'], roi['t']))    \n",
    "            \n",
    "            roi_detections = self.model.detect([image_roi], verbose=1)[0]            \n",
    "            self.collate_detections(roi, roi_detections)\n",
    "            \n",
    "            ax = display_instances(roi, res['rois'], res['masks'], res['class_ids'], \n",
    "                            ['BG', 'polygon'])\n",
    "            self.save_roi_detections(roi, ax)\n",
    "        ax = display_instances(self.img, self.all_rs['rois'], self.all_rs['masks'], \n",
    "                               self.all_rs['class_ids'], ['BG', 'polygon'])   \n",
    "        self.save_image_detections(ax)\n",
    "        self.save_data()\n",
    "    \n",
    "    def save_data(self):\n",
    "        # name contains 'image title';'chunking settings', 'overlapping settings'\n",
    "        new_csv_name ='{};[{},{},{}].csv'.format(self.image_title,self.rows, self.cols, self.overlap))\n",
    "        # save folder contains 'chunking settings', 'overlapping settings'\n",
    "        save_folder = os.path.join(this_image_dir, '[{},{},{}]'.format(self.rows, self.cols, self.overlap)), 'data')\n",
    "        \n",
    "        csv_file = os.path.join(save_folder, new_csv_name) \n",
    "        logging.info('Saving compressed data (csv and masks) to {}'.format(save_folder))\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        with open(csv_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['path','top', 'left', 'id'])\n",
    "            for idx, detection in enumerate(self.detection_data):\n",
    "                top, left = detection['topleft']\n",
    "                path = os.path.join(save_folder, '{}.png'.format(str(idx).zfill(5)))\n",
    "                writer.writerow([path, top, left, detection['id']])\n",
    "                cv2.imwrite(path, detection['outline'])\n",
    "\n",
    "    def save_roi_detections(self, roi, ax):\n",
    "\n",
    "        new_image_name ='{};({}-{})({}-{}).png'.format(self.image_title,roi['t'],roi['b'],roi['l'],roi['r'],self.image_ext)\n",
    "        # save folder contains 'chunking settings', 'overlapping settings'\n",
    "        save_folder = os.path.join(self.output_dir, '[{},{},{}]'.format(self.rows, self.cols, self.overlap), 'images')                  \n",
    "        save_path = os.path.join(save_folder, new_image_name)\n",
    "        logging.info('Saving image chunk to {}'.format(save_path))\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        plt.savefig(save_path)  \n",
    "\n",
    "    def save_image_detections(self, ax):\n",
    "        # name contains 'image title';'chunking settings', 'overlapping settings'\n",
    "        new_image_name ='{};[{},{},{}].png'.format(image_title,self.rows, self.cols, self.overlap)\n",
    "        # save folder contains 'chunking settings', 'overlapping settings'\n",
    "        save_folder = os.path.join(this_image_dir, '[{},{},{}]'.format(self.rows, self.cols, self.overlap))                 \n",
    "        save_path = os.path.join(save_folder, new_image_name)\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        plt.savefig(save_path)   \n",
    "            \n",
    "    def get_rois(self, image, rows=6, cols=6, overlap=0.1):\n",
    "        \n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.overlap = overlap\n",
    "        self.image_height, self.image_width = image.shape[:2]  \n",
    "        self.roi_width = int(self.image_width/self.cols)\n",
    "        self.roi_height = int(self.image_height/self.rows)\n",
    "        self.overlap_width = int(self.roi_width*self.overlap)\n",
    "        self.overlap_height = int(self.roi_height*self.overlap)        \n",
    "        self.roi_regions = []\n",
    "        \n",
    "        for n in range(rows):\n",
    "            #first divide image into n equal rows     \n",
    "            #roi rows without overlap\n",
    "            top1 = int(n * self.roi_height)\n",
    "            bottom1 = int(top1+self.roi_height)\n",
    "            #extend roi rows by overlap\n",
    "            top2 = max(0, top1-self.overlap_height)\n",
    "            bottom2 = min(self.image_height, bottom1+self.overlap_height)      \n",
    "            \n",
    "            for m in range(cols):\n",
    "                # then divide rows vertically m times to get roi chunk\n",
    "                #roi columns without overlap \n",
    "                left1 = int(m * self.roi_width)\n",
    "                right1 = int(left1+self.roi_width)\n",
    "                # roi columns with overlap\n",
    "                left2 = max(0, left1-self.overlap_width)\n",
    "                right2 = min(self.image_width, right1+self.overlap_width)\n",
    "                roi_data = {'t':top2, 'b':bottom2, 'l':left2, 'r':right2}\n",
    "                self.roi_regions.append(roi_data)\n",
    "               \n",
    "    def collate_detections(self, roi, detections):\n",
    "        collated_data = []\n",
    "        masks_in_chunk = detections['masks'].T\n",
    "        for idx in range(len(detections['rois'])):\n",
    "            ##### Deal with rois #####\n",
    "            # specify roi of current detection (top, left, bottom, right)\n",
    "\n",
    "            _t,_l,_b,_r = roi_in_chunk = detections['rois'][idx]\n",
    "\n",
    "            # get roi location in original image\n",
    "            t, b = [rownum + roi['t'] for rownum in [_t, _b]]\n",
    "            l, r = [colnum + roi['l'] for colnum in [_l, _r]]\n",
    "            roi_in_origin = np.array([t,l,b,r])\n",
    "\n",
    "            # append roi to dict for original image\n",
    "            self.all_rs['rois'] = np.vstack([self.all_rs['rois'], roi_in_origin])   \n",
    "\n",
    "            ##### Deal with masks #####\n",
    "            # specify mask of current detection\n",
    "            mask_in_chunk = masks_in_chunk[idx].T\n",
    "\n",
    "            # create a blank canvas to represent original image\n",
    "            mask_in_origin = np.zeros(self.img.shape[:2], np.uint8)\n",
    "            # put chunk into original position of canvas\n",
    "            mask_in_origin[roi['t']:roi['b'], roi['l']:roi['r']] = mask_in_chunk\n",
    "            # add mask to collated dict\n",
    "            self.all_rs['masks'] = np.dstack([self.all_rs['masks'], mask_in_origin])\n",
    "\n",
    "            # collate detection data in form that can be compressed easily\n",
    "            # note that maskrcnn flips the image horizontally, so this data points are also reversed\n",
    "            mask = mask_in_origin[t:b,l:r][:,::-1]\n",
    "            mask[mask == True] = 255\n",
    "\n",
    "            chunk_data = {'topleft':(t,self.image_width-r), \n",
    "                              'outline':mask, \n",
    "                              'id':detections['class_ids'][idx]}\n",
    "\n",
    "            self.detection_data.append(chunk_data)     \n",
    "\n",
    "TARGET_OBJECT = 'W19'   \n",
    "model_version = 0\n",
    "d = Detector(TARGET_OBJECT, model_version)\n",
    "input_path = '/mnt/orkney1/Chemobot/crystalbot_imgs/W19/20180214-0/Reaction_030/Images/Image_016.png'\n",
    "d.detect_path(input_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
